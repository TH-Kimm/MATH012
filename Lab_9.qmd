---
title: "Lab 9"
webr:
  show-startup-message: true
---

```{webr-r}
#| context: setup

library(fastGraph)
```
::: {.hidden}
\let\OldTexttt\texttt
\renewcommand{\txt}[1]{\OldTexttt{\color{brown}{#1}}}
:::

# Probability (II)

## Continuous Random Variable (RV)

While a discrete random variable only takes distinct values, a continuous random variable can take any value within its given range. For example, it might yield a value between 10 and 120 (such as the daily high temperature in the U.S.) or any value from 0 to infinity (such as the failure time of a particular device in minutes).

## Probability Distribution of Continuous RV

A continuous probability distribution can be represented as a curve $f(x)$ that spans the possible values of a random variable. Its shape can vary depending on the variable of interest, but it has the following properties: 

1. $f(x)\ge 0$ for all $x$;
2. The total area under the probability density curve is always 1; 
3. $P[ a\le X\le b ]$ is the area under the probability density curve between $a$ and $b$.
 

![](images/density.png){fig-align="center"}

## The Normal Distribution

In class, we primarily focus on the normal distribution because: 

- Many real-world phenomena follow a normal distribution, such as people's height, IQ scores, exam grades, snowflake sizes, measurement errors, and lightbulb lifetimes.
- The Central Limit Theorem ensures that sums and averages of independent random variables tend to be normally distributed.
- The normal distribution is mathematically convenient and easy to work with. In particular, we can always use $z$-table for any probability calculations.


A normal distribution can be characterized by two parameters: the mean $\mu$ and the variance $\sigma^2$ (or equivalently, the standard deviation $\sigma$).

![](images/normal.gif){fig-align="center"}

# Probability calculation

Probability calculations under a normal distribution can be easily performed using the function $\txt{pnorm(c)}$. Similar to using a $z$-table, this function provides the left-tail probability based on a cutoff value of $c$.

Suppose $X$ to be the \# of beer cans consumed by a female college student in a year. It is assumed to be normally distributed with the mean 260 and standard deviation 80. What we are interested in is the proportion of female students drink less than 300 beer cans per year.

```{webr-r}
# Given information
x <- 300
mu <- 260
sigma <- 80
# z-score
z <- (x-mu)/sigma

# Probability calculation
pnorm(z)

# Graphical Illustration
x <- -1000:1000/300
y <- dnorm(x)
shadeDist(z,"dnorm",0,1,col=c("black","brown"),main="Area under Standard Normal Curve",xmin=-3.5,xmax=3.5)
```

This approach precisely emulates the way we typically perform probability calculations using the $z$-table. Now, we can simplify the process by using the second and third arguments of the $\txt{pnorm()}$ function, which allow us to specify the mean and standard deviation of the distribution directly.

```{webr-r}
# Given information
x <- 300
mu <- 260
sigma <- 80

# Probability calculation
pnorm(x,mu,sigma)

# Graphical Illustration
x <- 260+(-1000:1000)/30
y <- dnorm(x)
shadeDist(300,"dnorm",260,80,col=c("black","brown"),main="Area under Standard Normal Curve")

```

## Example

Let $Y$ be the \# of beer cans consumed by a male college student in a year. It is assumed to be normally distributed with the mean 440 and standard deviation 60. What proportion of male students drink more than 365 beer cans per year?

```{webr-r}
y <-
mu <-
sigma <-
```

## Sampling Distribution for Sample Mean

The sampling distribution contains **all the information** about a statistic of interest. When examining the behavior of a sample mean randomly drawn from a population, we first consider the following properties:

-   The mean of "the sampling distribution for the sample mean" will always equal the population mean $\mu$: $$\mu_\bar{X}=E[\bar{X}]=\mu.$$
-   The standard deviation of "the sampling distribution for the sample mean" will equal the population standard deviation $\sigma$ over the square root of the sample size $n$: $$\sigma_\bar{X}=SD[\bar{X}]=\frac{\sigma}{\sqrt{n}}.$$

Then, the shape of the sampling distribution can be described as follows:

1.  If population distribution is a normal distribution, the sampling distribution for sample mean would resemble the shape of the population distribution. That is, the sampling distribution also follows a normal distribution with the above mean and standard deviation.

2.  If population distribution is unknown, the sampling distribution for sample mean would still follow a normal distribution with the above mean and standard deviation only if we have sufficiently large sample size, e.g., $n\ge 30$.

In particular, we call the second result **the central limit theorem (C.L.T.)**.

# Probability calculation

Suppose a test score has the mean value 78 and standard deviation 10. We don't have any other information regarding the population distribution. Let us consider the probability that a sample mean with the sample size $n=32$ is greater than 82.

```{webr-r}
# Given information
mu <- 78
sigma <- 10
n<-32
x <- 82

# the mean and standard deviation of the sampling distribution
mu_xbar <- mu
sigma_xbar <- 10/sqrt(32)

#Probability calculation based on the C.L.T.
1 - pnorm(x,mu_xbar,sigma_xbar)
```
Note that if the sample size were smaller than 30, the probability calculation would be impossible since the appropriate probability distribution for the computation would be unknown.


# Verification of C.L.T. through a simulation

Lastly, let us verify the central limit theorem through a short simulation. Here, we assume the population distribution is highly skewed to the right.

```{webr-r}
## C.L.T. Simulation for exponential population distributions
set.seed(2024)
m<-500
x<-1:10000/500

plot(x,dexp(x,1/9),lwd=3,type="l",main="Population distribution: Highly Skewed Version")
abline(v=9,col="blue",lwd=3,lty=2)
legend("topright",legend=c("true mean"),lwd=2,col=c("blue"),lty=2)

sam_dist_mean_exp<-function(N=30)
{
sample_means<-NULL
for(i in 1:m)
  sample_means[i]<-mean(rexp(N,1/9))
hist(sample_means,probability=TRUE,lwd=2,col="brown",main=paste("Sampling Dist'n of sample mean: n=",N),xlim=c(0,20))

abline(v=9,col="blue",lwd=2,lty=2)
curve(dnorm(x,9,9/sqrt(N)),add=TRUE,lwd=2)
}
par(mfrow=c(2,2))
sam_dist_mean_exp(2)
sam_dist_mean_exp(5)
sam_dist_mean_exp(15)
sam_dist_mean_exp(30)
par(mfrow=c(1,1))
```

Note that the shape of the histogram (the empirical sample mean distribution) converges toward the theoretical sampling distribution (represented by the black curve) as the sample size increases from $n=2$ to $n=30$.

## Lab Questions

1.  A survey indicates that the average American family produces 17.2 pounds of glass waste per year, with a population standard deviation of 2.5 pounds. Calculate the probability that the sample mean for a group of 55 families will fall between 17 and 18 pounds.

<!-- -->

i.  Can we use the C.L.T. for the probability calculation?\
    True / False

ii. Calculate the probability.

```{webr-r}

```

2.  The average teacher's salary in New Jersey is \$62,174, assuming a normal distribution with a standard deviation of \$8,500.

<!-- -->

i.  What is the probability that a randomly selected teacher makes less than \$60,000 per year?

```{webr-r}

```

ii. If we sample 100 teachers' salaries, what is the probability that the sample mean is less than \$60,000 per year?

```{webr-r}

```

iii. Why is the probability in part (i) higher than the probability in part (ii)?
